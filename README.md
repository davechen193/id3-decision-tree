# id3-decision-tree

Decision tree algorithm comparing with sklearn. Here the max-depth parameter is abandoned. Study on the information gain calculation is enhanced as we assume the features are iid and normal. In the future, further implementation can be done on non-normal features. Comparing with the kernel trick in SVM, the decision tree's handling of non-linearity is more rigid, but subsampling to find the best split is the crucial mathematical concept that can be learned from set theory. 
